{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"17gVcDvtSaRSH5GSLzVGTJrI-NrJBCMBs","authorship_tag":"ABX9TyOV2DZwFA58TI6Zu3YSr+kl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n8hJwufmpM2W","executionInfo":{"status":"ok","timestamp":1757096451172,"user_tz":0,"elapsed":104,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"e0eff239-1108-4210-e16a-f9c8e90fc7d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction: [0]\n"]}],"source":["\n","import joblib\n","\n","# Load models\n","knn_loaded = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/Stored/KNN/knn_tfidf_model.pkl\")\n","knn_count_loaded = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/Stored/KNN/knn_count_model.pkl\")\n","\n","# Load vectorizers\n","tfidf_loaded = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/Stored/KNN/tfidf_vectorizer.pkl\")\n","count_vec_loaded = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/Stored/KNN/count_vectorizer.pkl\")\n","\n","# Example prediction with TF-IDF KNN\n","new_text = [\"\"\"The World Health Organization declared COVID-19 a global pandemic on March 11, 2020, after the coronavirus spread rapidly across multiple continents. Governments around the world responded by implementing lockdowns, social distancing, and mask mandates to slow transmission.\n","\n","By late 2020, pharmaceutical companies including Pfizer-BioNTech and Moderna developed mRNA vaccines, which were granted emergency use authorization in several countries. Large-scale vaccination campaigns began in December 2020, marking a major milestone in the global fight against the pandemic.\"\"\"]\n","X_new = tfidf_loaded.transform(new_text)\n","prediction = knn_loaded.predict(X_new)\n","\n","print(\"Prediction:\", prediction)  # 0 = Fake, 1 = Real\n"]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"U88UIz_AvA_u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","# Load CSV\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Binned/ankasa.csv\")\n","\n","\n","# Drop rows where 'content' or 'label' is missing\n","df = df.dropna(subset=[\"content\", \"label\"])\n","\n","df.to_csv(\"ankasa.csv\", index=False)\n","\n","\n","\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","\n","# Load dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Binned/ankasa.csv\")\n","\n","# Extract content and labels\n","texts = df['content'].astype(str)  # ensure text format\n","labels = df['label']\n","\n","# Initialize vectorizers\n","tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)  # limit features if needed\n","count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n","\n","# Fit and transform data\n","X_tfidf = tfidf_vectorizer.fit_transform(texts)\n","X_count = count_vectorizer.fit_transform(texts)\n","\n","print(\"TF-IDF Shape:\", X_tfidf.shape)\n","print(\"Count Vectorizer Shape:\", X_count.shape)\n","\n","# Example: check vocabulary sizes\n","print(\"TF-IDF Vocabulary Size:\", len(tfidf_vectorizer.vocabulary_))\n","print(\"Count Vocabulary Size:\", len(count_vectorizer.vocabulary_))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MnPb121cvPIU","executionInfo":{"status":"ok","timestamp":1757409665786,"user_tz":0,"elapsed":414,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"cf05bd60-bf16-4e4f-d7e4-d5f7c91fc1d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TF-IDF Shape: (9948, 5000)\n","Count Vectorizer Shape: (9948, 5000)\n","TF-IDF Vocabulary Size: 5000\n","Count Vocabulary Size: 5000\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.metrics import accuracy_score\n","\n","# Load dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Binned/ankasa.csv\")\n","\n","# Extract features and labels\n","texts = df['content'].astype(str)\n","labels = df['label']\n","\n","# Vectorizers\n","tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n","count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n","\n","# Transform\n","X_tfidf = tfidf_vectorizer.fit_transform(texts)\n","X_count = count_vectorizer.fit_transform(texts)\n","\n","# Train-test split (80/20)\n","X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(\n","    X_tfidf, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","X_train_count, X_test_count, _, _ = train_test_split(\n","    X_count, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","\n","# ----------------------\n","# Grid Search for K (TF-IDF)\n","# ----------------------\n","param_grid = {'n_neighbors': [5, 10, 20, 50, 100]}\n","grid_tfidf = GridSearchCV(KNeighborsClassifier(n_jobs=-1), param_grid, cv=3, scoring='accuracy')\n","grid_tfidf.fit(X_train_tfidf, y_train)\n","print(\"Best K (TF-IDF):\", grid_tfidf.best_params_)\n","print(\"Best CV Accuracy (TF-IDF):\", grid_tfidf.best_score_)\n","\n","# ----------------------\n","# Final KNN (TF-IDF, K=10)\n","# ----------------------\n","knn_tfidf = KNeighborsClassifier(n_neighbors=10, n_jobs=-1)\n","knn_tfidf.fit(X_train_tfidf, y_train)\n","\n","train_acc_tfidf = accuracy_score(y_train, knn_tfidf.predict(X_train_tfidf))\n","test_acc_tfidf = accuracy_score(y_test, knn_tfidf.predict(X_test_tfidf))\n","\n","print(\"\\nKNN with TF-IDF\")\n","print(\"Training Accuracy:\", round(train_acc_tfidf * 100, 2), \"%\")\n","print(\"Testing Accuracy:\", round(test_acc_tfidf * 100, 2), \"%\")\n","\n","# ----------------------\n","# Final KNN (Count Vectorizer, K=10)\n","# ----------------------\n","knn_count = KNeighborsClassifier(n_neighbors=10, n_jobs=-1)\n","knn_count.fit(X_train_count, y_train)\n","\n","train_acc_count = accuracy_score(y_train, knn_count.predict(X_train_count))\n","test_acc_count = accuracy_score(y_test, knn_count.predict(X_test_count))\n","\n","print(\"\\nKNN with Count Vectorizer\")\n","print(\"Training Accuracy:\", round(train_acc_count * 100, 2), \"%\")\n","print(\"Testing Accuracy:\", round(test_acc_count * 100, 2), \"%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFmHIArgykAp","executionInfo":{"status":"ok","timestamp":1757409880473,"user_tz":0,"elapsed":20972,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"13d22ccc-e7d5-42d4-e764-eb0f2b4990b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best K (TF-IDF): {'n_neighbors': 5}\n","Best CV Accuracy (TF-IDF): 0.8051018255891762\n","\n","KNN with TF-IDF\n","Training Accuracy: 82.16 %\n","Testing Accuracy: 80.4 %\n","\n","KNN with Count Vectorizer\n","Training Accuracy: 76.35 %\n","Testing Accuracy: 75.63 %\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.metrics import accuracy_score, f1_score, classification_report\n","from imblearn.over_sampling import SMOTE\n","from imblearn.pipeline import Pipeline\n","\n","# Load dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Binned/ankasa.csv\")\n","\n","# Extract features and labels\n","texts = df['content'].astype(str)\n","labels = df['label']\n","\n","# Vectorizers\n","tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n","count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n","\n","# Transform\n","X_tfidf = tfidf_vectorizer.fit_transform(texts)\n","X_count = count_vectorizer.fit_transform(texts)\n","\n","# Train-test split (80/20)\n","X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(\n","    X_tfidf, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","X_train_count, X_test_count, _, _ = train_test_split(\n","    X_count, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","\n","# ----------------------\n","# SMOTE + KNN Pipeline (TF-IDF)\n","# ----------------------\n","smote = SMOTE(random_state=42)\n","\n","knn_tfidf = KNeighborsClassifier(n_neighbors=10, weights='distance', n_jobs=-1)\n","pipeline_tfidf = Pipeline([\n","    ('smote', smote),\n","    ('knn', knn_tfidf)\n","])\n","\n","pipeline_tfidf.fit(X_train_tfidf, y_train)\n","\n","y_pred_train_tfidf = pipeline_tfidf.predict(X_train_tfidf)\n","y_pred_test_tfidf = pipeline_tfidf.predict(X_test_tfidf)\n","\n","print(\"\\nKNN with TF-IDF + SMOTE + distance weighting\")\n","print(\"Training Accuracy:\", round(accuracy_score(y_train, y_pred_train_tfidf) * 100, 2), \"%\")\n","print(\"Testing Accuracy:\", round(accuracy_score(y_test, y_pred_test_tfidf) * 100, 2), \"%\")\n","print(\"Testing F1-Score:\", round(f1_score(y_test, y_pred_test_tfidf) * 100, 2), \"%\")\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test_tfidf))\n","\n","# ----------------------\n","# SMOTE + KNN Pipeline (Count Vectorizer)\n","# ----------------------\n","knn_count = KNeighborsClassifier(n_neighbors=10, weights='distance', n_jobs=-1)\n","pipeline_count = Pipeline([\n","    ('smote', smote),\n","    ('knn', knn_count)\n","])\n","\n","pipeline_count.fit(X_train_count, y_train)\n","\n","y_pred_train_count = pipeline_count.predict(X_train_count)\n","y_pred_test_count = pipeline_count.predict(X_test_count)\n","\n","print(\"\\nKNN with Count Vectorizer + SMOTE + distance weighting\")\n","print(\"Training Accuracy:\", round(accuracy_score(y_train, y_pred_train_count) * 100, 2), \"%\")\n","print(\"Testing Accuracy:\", round(accuracy_score(y_test, y_pred_test_count) * 100, 2), \"%\")\n","print(\"Testing F1-Score:\", round(f1_score(y_test, y_pred_test_count) * 100, 2), \"%\")\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test_count))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TL4vmTj8NAbk","executionInfo":{"status":"ok","timestamp":1757500701930,"user_tz":0,"elapsed":13676,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"6611a66c-2aee-4618-d5d5-66c95b597ddd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","KNN with TF-IDF + SMOTE + distance weighting\n","Training Accuracy: 99.96 %\n","Testing Accuracy: 84.72 %\n","Testing F1-Score: 76.79 %\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      0.80      0.89      1482\n","           1       0.63      0.99      0.77       508\n","\n","    accuracy                           0.85      1990\n","   macro avg       0.81      0.89      0.83      1990\n","weighted avg       0.90      0.85      0.86      1990\n","\n","\n","KNN with Count Vectorizer + SMOTE + distance weighting\n","Training Accuracy: 99.72 %\n","Testing Accuracy: 85.13 %\n","Testing F1-Score: 77.16 %\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.99      0.81      0.89      1482\n","           1       0.63      0.98      0.77       508\n","\n","    accuracy                           0.85      1990\n","   macro avg       0.81      0.89      0.83      1990\n","weighted avg       0.90      0.85      0.86      1990\n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.metrics import classification_report, f1_score, accuracy_score\n","from imblearn.over_sampling import SMOTE\n","from imblearn.pipeline import Pipeline\n","\n","# ----------------------\n","# Load dataset\n","# ----------------------\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Binned/ankasa.csv\")\n","texts = df['content'].astype(str)\n","labels = df['label']\n","\n","# ----------------------\n","# Vectorizers\n","# ----------------------\n","tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n","count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n","\n","X_tfidf = tfidf_vectorizer.fit_transform(texts)\n","X_count = count_vectorizer.fit_transform(texts)\n","\n","# ----------------------\n","# Train-test split (80/20)\n","# ----------------------\n","X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(\n","    X_tfidf, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","X_train_count, X_test_count, _, _ = train_test_split(\n","    X_count, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","\n","# ----------------------\n","# GridSearchCV Parameters\n","# Only use metrics compatible with sparse input\n","# ----------------------\n","param_grid = {\n","    'knn__n_neighbors': [5, 10, 20, 50, 100],\n","    'knn__metric': ['euclidean', 'manhattan']\n","}\n","\n","# ----------------------\n","# SMOTE + KNN Pipeline Function\n","# ----------------------\n","def run_knn_pipeline(X_train, X_test, y_train, y_test, vectorizer_name=\"TF-IDF\"):\n","    smote = SMOTE(random_state=42)\n","    knn = KNeighborsClassifier(weights='distance', n_jobs=-1)\n","\n","    pipeline = Pipeline([\n","        ('smote', smote),\n","        ('knn', knn)\n","    ])\n","\n","    grid = GridSearchCV(\n","        pipeline,\n","        param_grid,\n","        cv=3,\n","        scoring='f1',\n","        n_jobs=-1,\n","        verbose=2\n","    )\n","\n","    grid.fit(X_train, y_train)\n","\n","    # Evaluation\n","    y_pred = grid.predict(X_test)\n","    print(f\"\\nBest Parameters ({vectorizer_name}): {grid.best_params_}\")\n","    print(f\"Best CV F1-Score ({vectorizer_name}): {grid.best_score_:.2f}\")\n","    print(f\"{vectorizer_name} Test Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n","    print(f\"{vectorizer_name} Test F1-Score: {f1_score(y_test, y_pred):.2f}\")\n","    print(f\"\\nClassification Report ({vectorizer_name}):\\n{classification_report(y_test, y_pred)}\")\n","\n","# ----------------------\n","# Run TF-IDF KNN\n","# ----------------------\n","run_knn_pipeline(X_train_tfidf, X_test_tfidf, y_train, y_test, vectorizer_name=\"TF-IDF\")\n","\n","# ----------------------\n","# Run Count Vectorizer KNN\n","# ----------------------\n","run_knn_pipeline(X_train_count, X_test_count, y_train, y_test, vectorizer_name=\"Count\")\n"],"metadata":{"id":"itd6BiV9p7MZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757502469173,"user_tz":0,"elapsed":62085,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"4a8c305c-6286-47a6-9d37-994e79fcc7e1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","\n","Best Parameters (TF-IDF): {'knn__metric': 'euclidean', 'knn__n_neighbors': 5}\n","Best CV F1-Score (TF-IDF): 0.66\n","TF-IDF Test Accuracy: 0.86\n","TF-IDF Test F1-Score: 0.79\n","\n","Classification Report (TF-IDF):\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.82      0.90      1482\n","           1       0.65      0.99      0.79       508\n","\n","    accuracy                           0.86      1990\n","   macro avg       0.82      0.90      0.84      1990\n","weighted avg       0.91      0.86      0.87      1990\n","\n","Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","\n","Best Parameters (Count): {'knn__metric': 'manhattan', 'knn__n_neighbors': 5}\n","Best CV F1-Score (Count): 0.62\n","Count Test Accuracy: 0.86\n","Count Test F1-Score: 0.79\n","\n","Classification Report (Count):\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.82      0.90      1482\n","           1       0.66      0.98      0.79       508\n","\n","    accuracy                           0.86      1990\n","   macro avg       0.82      0.90      0.84      1990\n","weighted avg       0.91      0.86      0.87      1990\n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics import classification_report, f1_score, accuracy_score\n","from imblearn.over_sampling import SMOTE\n","from imblearn.pipeline import Pipeline\n","\n","# ----------------------\n","# Load dataset\n","# ----------------------\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Binned/ankasa.csv\")\n","texts = df['content'].astype(str)\n","labels = df['label']\n","\n","# ----------------------\n","# TF-IDF Vectorization\n","# ----------------------\n","tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n","X_tfidf = tfidf_vectorizer.fit_transform(texts)\n","\n","# ----------------------\n","# Train-test split (80/20)\n","# ----------------------\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_tfidf, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","\n","# ----------------------\n","# SMOTE + Random Forest Pipeline\n","# ----------------------\n","smote = SMOTE(random_state=42)\n","rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n","\n","pipeline = Pipeline([\n","    ('smote', smote),\n","    ('rf', rf)\n","])\n","\n","# ----------------------\n","# GridSearchCV Hyperparameters\n","# ----------------------\n","param_grid = {\n","    'rf__n_estimators': [100, 200, 500],\n","    'rf__max_depth': [None, 10, 20],\n","    'rf__min_samples_split': [2, 5],\n","    'rf__min_samples_leaf': [1, 2]\n","}\n","\n","grid = GridSearchCV(\n","    pipeline,\n","    param_grid,\n","    cv=3,\n","    scoring='f1',\n","    n_jobs=-1,\n","    verbose=2\n",")\n","\n","# ----------------------\n","# Fit the model\n","# ----------------------\n","grid.fit(X_train, y_train)\n","\n","# ----------------------\n","# Evaluation\n","# ----------------------\n","y_pred = grid.predict(X_test)\n","print(\"Best Parameters (Random Forest):\", grid.best_params_)\n","print(\"Best CV F1-Score:\", round(grid.best_score_ * 100, 2), \"%\")\n","print(\"Test Accuracy:\", round(accuracy_score(y_test, y_pred) * 100, 2), \"%\")\n","print(\"Test F1-Score:\", round(f1_score(y_test, y_pred) * 100, 2), \"%\")\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghUYAZ43N52W","executionInfo":{"status":"ok","timestamp":1757503352667,"user_tz":0,"elapsed":485036,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"2d99c45a-1346-443c-9197-30c06f24c48c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 36 candidates, totalling 108 fits\n","Best Parameters (Random Forest): {'rf__max_depth': None, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 500}\n","Best CV F1-Score: 74.24 %\n","Test Accuracy: 91.46 %\n","Test F1-Score: 81.8 %\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.92      0.97      0.94      1482\n","           1       0.90      0.75      0.82       508\n","\n","    accuracy                           0.91      1990\n","   macro avg       0.91      0.86      0.88      1990\n","weighted avg       0.91      0.91      0.91      1990\n","\n"]}]},{"cell_type":"code","source":["import os\n","import joblib\n","\n","# ----------------------\n","# Define checkpoint folder\n","# ----------------------\n","CHECKPOINT_DIR = \"/content/drive/MyDrive/Colab Notebooks/Checkpoints/RF\"\n","os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n","\n","# ----------------------\n","# Save the trained model\n","# ----------------------\n","model_path = os.path.join(CHECKPOINT_DIR, \"rf_smote_tfidf.pkl\")\n","joblib.dump(grid.best_estimator_, model_path)\n","\n","print(f\"Model saved at: {model_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fICp95LSVYdA","executionInfo":{"status":"ok","timestamp":1757503554714,"user_tz":0,"elapsed":1949,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"4a9b5f19-be52-4364-c81f-e58cafd68e24"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved at: /content/drive/MyDrive/Colab Notebooks/Checkpoints/RF/rf_smote_tfidf.pkl\n"]}]},{"cell_type":"code","source":["import joblib\n","from sklearn.pipeline import Pipeline\n","\n","# After training RF with SMOTE\n","# Assume `grid.best_estimator_` is your SMOTE + RF pipeline\n","\n","# Extract the trained Random Forest\n","trained_rf = grid.best_estimator_['rf']  # King, this is the RF classifier after SMOTE training\n","\n","# Save TF-IDF vectorizer separately\n","tfidf_vectorizer = grid.best_estimator_['smote'].fit_resample  # Actually keep your original TF-IDF\n","# But safer: just save the vectorizer you already used\n","tfidf_vectorizer_path = \"/content/drive/MyDrive/Colab Notebooks/Checkpoints/RF/tfidf_vectorizer.pkl\"\n","joblib.dump(tfidf_vectorizer, tfidf_vectorizer_path)\n","\n","# Create a clean inference pipeline: TF-IDF + trained RF\n","inference_pipeline = Pipeline([\n","    ('tfidf', tfidf_vectorizer),\n","    ('rf', trained_rf)\n","])\n","\n","# Save the inference pipeline\n","inference_model_path = \"/content/drive/MyDrive/Colab Notebooks/Checkpoints/RF/rf_inference.pkl\"\n","joblib.dump(inference_pipeline, inference_model_path)\n","\n","print(\"Inference pipeline saved at:\", inference_model_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HQSweCuJYrmM","executionInfo":{"status":"ok","timestamp":1757503738548,"user_tz":0,"elapsed":834,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"b8542dbe-c6f9-4955-d455-fab9e9adc657"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Inference pipeline saved at: /content/drive/MyDrive/Colab Notebooks/Checkpoints/RF/rf_inference.pkl\n"]}]},{"cell_type":"code","source":["import joblib\n","from sklearn.pipeline import Pipeline\n","\n","# Paths\n","CHECKPOINT_DIR = \"/content/drive/MyDrive/Colab Notebooks/Checkpoints/RF\"\n","tfidf_vectorizer_path = f\"{CHECKPOINT_DIR}/tfidf_vectorizer.pkl\"  # Your fitted TF-IDF\n","inference_model_path = f\"{CHECKPOINT_DIR}/rf_inference.pkl\"\n","\n","# Load the TF-IDF vectorizer\n","tfidf_vectorizer = joblib.load(tfidf_vectorizer_path)\n","\n","# Extract the trained RF classifier from your SMOTE pipeline\n","trained_rf = grid.best_estimator_['rf']  # The Random Forest classifier\n","\n","# Build a proper inference pipeline\n","inference_pipeline = Pipeline([\n","    ('tfidf', tfidf_vectorizer),\n","    ('rf', trained_rf)\n","])\n","\n","# Save the inference pipeline\n","joblib.dump(inference_pipeline, inference_model_path)\n","print(\"Inference pipeline saved at:\", inference_model_path)\n","\n","# ----------------------\n","# Predict\n","# ----------------------\n","model = joblib.load(inference_model_path)\n","new_text = [\"Coronavirus is a hoax\"]\n","prediction = model.predict(new_text)\n","prediction_proba = model.predict_proba(new_text)\n","\n","print(\"Predicted label:\", prediction[0])\n","print(\"Prediction probabilities:\", prediction_proba[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"id":"BP-UvPiIX_ud","executionInfo":{"status":"error","timestamp":1757503853979,"user_tz":0,"elapsed":2201,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"d4a0a8b2-d588-42db-e951-5e7b6cee53f6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Inference pipeline saved at: /content/drive/MyDrive/Colab Notebooks/Checkpoints/RF/rf_inference.pkl\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'function' object has no attribute 'transform'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1403208003.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mnew_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Coronavirus is a hoax\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprediction_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                     \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'transform'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"P8b3E1VaYLNe"},"execution_count":null,"outputs":[]}]}