{"cells":[{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score\n","\n","# Load dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Binned/ankasa.csv\")\n","\n","# Extract features and labels\n","texts = df['content'].astype(str)\n","labels = df['label']\n","\n","# Vectorizers\n","tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n","count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n","\n","# Transform\n","X_tfidf = tfidf_vectorizer.fit_transform(texts)\n","X_count = count_vectorizer.fit_transform(texts)\n","\n","# Train-test split (80/20)\n","X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(\n","    X_tfidf, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","X_train_count, X_test_count, _, _ = train_test_split(\n","    X_count, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","\n","# ----------------------\n","# Multinomial Naive Bayes with TF-IDF\n","# ----------------------\n","nb_tfidf = MultinomialNB()\n","nb_tfidf.fit(X_train_tfidf, y_train)\n","\n","train_acc_tfidf = accuracy_score(y_train, nb_tfidf.predict(X_train_tfidf))\n","test_acc_tfidf = accuracy_score(y_test, nb_tfidf.predict(X_test_tfidf))\n","\n","print(\"Naive Bayes with TF-IDF\")\n","print(\"Training Accuracy:\", round(train_acc_tfidf * 100, 2), \"%\")\n","print(\"Testing Accuracy:\", round(test_acc_tfidf * 100, 2), \"%\")\n","\n","# ----------------------\n","# Multinomial Naive Bayes with Count Vectorizer\n","# ----------------------\n","nb_count = MultinomialNB()\n","nb_count.fit(X_train_count, y_train)\n","\n","train_acc_count = accuracy_score(y_train, nb_count.predict(X_train_count))\n","test_acc_count = accuracy_score(y_test, nb_count.predict(X_test_count))\n","\n","print(\"\\nNaive Bayes with Count Vectorizer\")\n","print(\"Training Accuracy:\", round(train_acc_count * 100, 2), \"%\")\n","print(\"Testing Accuracy:\", round(test_acc_count * 100, 2), \"%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XbVMqAc1UOW","executionInfo":{"status":"ok","timestamp":1757410650703,"user_tz":0,"elapsed":1523,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"9d4bd340-3d6c-4aac-ee8e-6c8f0a2fd973"},"id":"2XbVMqAc1UOW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes with TF-IDF\n","Training Accuracy: 88.77 %\n","Testing Accuracy: 85.33 %\n","\n","Naive Bayes with Count Vectorizer\n","Training Accuracy: 91.57 %\n","Testing Accuracy: 86.68 %\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import classification_report\n","\n","# Load dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Binned/ankasa.csv\")\n","\n","# Extract features and labels\n","texts = df['content'].astype(str)\n","labels = df['label']\n","\n","# Vectorizers\n","tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n","count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n","\n","# Transform\n","X_tfidf = tfidf_vectorizer.fit_transform(texts)\n","X_count = count_vectorizer.fit_transform(texts)\n","\n","# Train-test split (80/20)\n","X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(\n","    X_tfidf, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","X_train_count, X_test_count, _, _ = train_test_split(\n","    X_count, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","\n","# Compute sample weights to handle imbalance\n","weight_real = len(y_train) / (2 * sum(y_train == 1))\n","weight_fake = len(y_train) / (2 * sum(y_train == 0))\n","sample_weights = np.array([weight_real if y==1 else weight_fake for y in y_train])\n","\n","# ----------------------\n","# Multinomial Naive Bayes with TF-IDF (weighted)\n","# ----------------------\n","nb_tfidf = MultinomialNB()\n","nb_tfidf.fit(X_train_tfidf, y_train, sample_weight=sample_weights)\n","\n","y_train_pred_tfidf = nb_tfidf.predict(X_train_tfidf)\n","y_test_pred_tfidf = nb_tfidf.predict(X_test_tfidf)\n","\n","print(\"Naive Bayes with TF-IDF (Weighted)\")\n","print(\"\\nTraining Metrics:\\n\", classification_report(y_train, y_train_pred_tfidf))\n","print(\"Testing Metrics:\\n\", classification_report(y_test, y_test_pred_tfidf))\n","\n","# ----------------------\n","# Multinomial Naive Bayes with Count Vectorizer (weighted)\n","# ----------------------\n","nb_count = MultinomialNB()\n","nb_count.fit(X_train_count, y_train, sample_weight=sample_weights)\n","\n","y_train_pred_count = nb_count.predict(X_train_count)\n","y_test_pred_count = nb_count.predict(X_test_count)\n","\n","print(\"\\nNaive Bayes with Count Vectorizer (Weighted)\")\n","print(\"\\nTraining Metrics:\\n\", classification_report(y_train, y_train_pred_count))\n","print(\"Testing Metrics:\\n\", classification_report(y_test, y_test_pred_count))\n"],"metadata":{"id":"vodf_Ouc1ZQa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757508352312,"user_tz":0,"elapsed":1560,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"752ae490-e84c-41e3-cf27-19ff6552152d"},"id":"vodf_Ouc1ZQa","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes with TF-IDF (Weighted)\n","\n","Training Metrics:\n","               precision    recall  f1-score   support\n","\n","           0       0.98      0.88      0.92      5929\n","           1       0.72      0.93      0.82      2029\n","\n","    accuracy                           0.89      7958\n","   macro avg       0.85      0.91      0.87      7958\n","weighted avg       0.91      0.89      0.90      7958\n","\n","Testing Metrics:\n","               precision    recall  f1-score   support\n","\n","           0       0.95      0.84      0.89      1482\n","           1       0.66      0.88      0.75       508\n","\n","    accuracy                           0.85      1990\n","   macro avg       0.81      0.86      0.82      1990\n","weighted avg       0.88      0.85      0.86      1990\n","\n","\n","Naive Bayes with Count Vectorizer (Weighted)\n","\n","Training Metrics:\n","               precision    recall  f1-score   support\n","\n","           0       0.97      0.88      0.92      5929\n","           1       0.73      0.92      0.81      2029\n","\n","    accuracy                           0.89      7958\n","   macro avg       0.85      0.90      0.87      7958\n","weighted avg       0.91      0.89      0.90      7958\n","\n","Testing Metrics:\n","               precision    recall  f1-score   support\n","\n","           0       0.93      0.85      0.89      1482\n","           1       0.66      0.82      0.73       508\n","\n","    accuracy                           0.85      1990\n","   macro avg       0.80      0.84      0.81      1990\n","weighted avg       0.86      0.85      0.85      1990\n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import classification_report\n","\n","# Load dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Binned/ankasa.csv\")\n","\n","# Extract features and labels\n","texts = df['content'].astype(str)\n","labels = df['label']\n","\n","# TF-IDF Vectorizer with bigrams and more features\n","tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=15000, ngram_range=(1,2))\n","X_tfidf = tfidf_vectorizer.fit_transform(texts)\n","\n","# Train-test split (80/20)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_tfidf, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","\n","# Compute sample weights to handle imbalance\n","weight_real = len(y_train) / (2 * sum(y_train == 1))\n","weight_fake = len(y_train) / (2 * sum(y_train == 0))\n","sample_weights = np.array([weight_real if y==1 else weight_fake for y in y_train])\n","\n","# Train Naive Bayes\n","nb_tfidf = MultinomialNB()\n","nb_tfidf.fit(X_train, y_train, sample_weight=sample_weights)\n","\n","# Predict probabilities\n","y_test_probs = nb_tfidf.predict_proba(X_test)[:,1]  # probability for class 1 (real news)\n","\n","# Adjust threshold for minority class\n","threshold = 0.45  # can be tuned\n","y_test_pred = (y_test_probs >= threshold).astype(int)\n","\n","y_train_probs = nb_tfidf.predict_proba(X_train)[:,1]\n","y_train_pred = (y_train_probs >= threshold).astype(int)\n","\n","# Evaluation\n","print(\"Naive Bayes TF-IDF (Weighted + Bigrams + Threshold Adjustment)\")\n","print(\"\\nTraining Metrics:\\n\", classification_report(y_train, y_train_pred))\n","print(\"Testing Metrics:\\n\", classification_report(y_test, y_test_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Ztjnn2oqpk8","executionInfo":{"status":"ok","timestamp":1757508446760,"user_tz":0,"elapsed":1080,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"10e14012-1aee-407c-9fac-fc731d64b8c4"},"id":"2Ztjnn2oqpk8","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes TF-IDF (Weighted + Bigrams + Threshold Adjustment)\n","\n","Training Metrics:\n","               precision    recall  f1-score   support\n","\n","           0       0.99      0.85      0.92      5929\n","           1       0.69      0.98      0.81      2029\n","\n","    accuracy                           0.88      7958\n","   macro avg       0.84      0.92      0.86      7958\n","weighted avg       0.92      0.88      0.89      7958\n","\n","Testing Metrics:\n","               precision    recall  f1-score   support\n","\n","           0       0.97      0.79      0.87      1482\n","           1       0.60      0.93      0.73       508\n","\n","    accuracy                           0.82      1990\n","   macro avg       0.79      0.86      0.80      1990\n","weighted avg       0.88      0.82      0.83      1990\n","\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import f1_score\n","\n","# Predict probabilities for real news class\n","y_probs = nb_tfidf.predict_proba(X_test)[:, 1]\n","\n","# Search for the threshold that maximizes F1-score\n","thresholds = np.linspace(0.1, 0.9, 81)  # from 0.1 to 0.9 in steps of 0.01\n","f1_scores = []\n","\n","for t in thresholds:\n","    y_pred_thresh = (y_probs >= t).astype(int)\n","    f1 = f1_score(y_test, y_pred_thresh, pos_label=1)\n","    f1_scores.append(f1)\n","\n","# Best threshold\n","best_idx = np.argmax(f1_scores)\n","best_threshold = thresholds[best_idx]\n","best_f1 = f1_scores[best_idx]\n","\n","print(f\"Optimal Threshold: {best_threshold:.2f}\")\n","print(f\"Best F1-score for Real News: {best_f1:.3f}\")\n","\n","# Predict using the best threshold\n","y_test_pred_opt = (y_probs >= best_threshold).astype(int)\n","\n","# Final evaluation report\n","from sklearn.metrics import classification_report\n","print(\"\\nFinal Metrics with Optimal Threshold:\")\n","print(classification_report(y_test, y_test_pred_opt))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykvkj6GXqqSn","executionInfo":{"status":"ok","timestamp":1757508520469,"user_tz":0,"elapsed":567,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"d3a5cd71-3fee-4ece-fcae-c8eadcb514f2"},"id":"ykvkj6GXqqSn","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimal Threshold: 0.58\n","Best F1-score for Real News: 0.787\n","\n","Final Metrics with Optimal Threshold:\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.90      0.92      1482\n","           1       0.74      0.85      0.79       508\n","\n","    accuracy                           0.88      1990\n","   macro avg       0.84      0.87      0.85      1990\n","weighted avg       0.89      0.88      0.89      1990\n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import classification_report, f1_score\n","\n","class WeightedNBDetector:\n","    def __init__(self, max_features=15000, ngram_range=(1,2)):\n","        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=max_features, ngram_range=ngram_range)\n","        self.model = MultinomialNB()\n","        self.threshold = 0.5  # default threshold\n","        self.fitted = False\n","\n","    def fit(self, texts, labels):\n","        # Vectorize\n","        X = self.vectorizer.fit_transform(texts)\n","\n","        # Train-test split\n","        X_train, X_test, y_train, y_test = train_test_split(\n","            X, labels, test_size=0.2, random_state=42, stratify=labels\n","        )\n","\n","        # Compute sample weights for imbalance\n","        weight_real = len(y_train) / (2 * sum(y_train == 1))\n","        weight_fake = len(y_train) / (2 * sum(y_train == 0))\n","        sample_weights = np.array([weight_real if y==1 else weight_fake for y in y_train])\n","\n","        # Train Naive Bayes\n","        self.model.fit(X_train, y_train, sample_weight=sample_weights)\n","\n","        # Optimize threshold for class 1 (real news)\n","        y_probs = self.model.predict_proba(X_test)[:,1]\n","        thresholds = np.linspace(0.1, 0.9, 81)\n","        f1_scores = [f1_score(y_test, (y_probs >= t).astype(int), pos_label=1) for t in thresholds]\n","        best_idx = np.argmax(f1_scores)\n","        self.threshold = thresholds[best_idx]\n","\n","        # Evaluate\n","        y_test_pred = (y_probs >= self.threshold).astype(int)\n","        print(f\"Optimal Threshold for Real News: {self.threshold:.2f}\")\n","        print(\"Test Metrics with Optimal Threshold:\")\n","        print(classification_report(y_test, y_test_pred))\n","\n","        self.fitted = True\n","        return self\n","\n","    def predict(self, texts):\n","        if not self.fitted:\n","            raise ValueError(\"Model is not fitted yet. Call fit() first.\")\n","        X = self.vectorizer.transform(texts)\n","        probs = self.model.predict_proba(X)[:,1]\n","        return (probs >= self.threshold).astype(int)\n","\n","    def predict_proba(self, texts):\n","        if not self.fitted:\n","            raise ValueError(\"Model is not fitted yet. Call fit() first.\")\n","        X = self.vectorizer.transform(texts)\n","        return self.model.predict_proba(X)\n","\n","# -------------------------\n","# Usage\n","# -------------------------\n","# Load your dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Binned/ankasa.csv\")\n","texts = df['content'].astype(str)\n","labels = df['label']\n","\n","# Initialize and train\n","detector = WeightedNBDetector()\n","detector.fit(texts, labels)\n","\n","# Predict on new texts\n","# new_texts = [\"Some news article here...\", \"Another example...\"]\n","# predictions = detector.predict(new_texts)\n","# probabilities = detector.predict_proba(new_texts)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYWTUBpBq8aY","executionInfo":{"status":"ok","timestamp":1757508590656,"user_tz":0,"elapsed":1993,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"508d24f2-c930-43db-df02-7fd5ef3a49fc"},"id":"fYWTUBpBq8aY","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimal Threshold for Real News: 0.58\n","Test Metrics with Optimal Threshold:\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.90      0.92      1482\n","           1       0.74      0.85      0.79       508\n","\n","    accuracy                           0.88      1990\n","   macro avg       0.84      0.87      0.85      1990\n","weighted avg       0.89      0.88      0.89      1990\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["<__main__.WeightedNBDetector at 0x7e3dfdf75550>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import joblib\n","import os\n","\n","# Path to save the model\n","folder_path = \"/content/drive/MyDrive/Colab Notebooks/Checkpoints/NB\"\n","save_path = os.path.join(folder_path, \"weighted_nb_detector.pkl\")\n","\n","# Create folder if it doesn't exist\n","os.makedirs(folder_path, exist_ok=True)\n","\n","# Save the entire detector object\n","joblib.dump(detector, save_path)\n","print(f\"Model saved to {save_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GDFMIo8krNMO","executionInfo":{"status":"ok","timestamp":1757508886132,"user_tz":0,"elapsed":265,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"7a446e7c-6d33-4a32-9417-bb5ca683fd1f"},"id":"GDFMIo8krNMO","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved to /content/drive/MyDrive/Colab Notebooks/Checkpoints/NB/weighted_nb_detector.pkl\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ksygTYxzrruY","executionInfo":{"status":"ok","timestamp":1757509100175,"user_tz":0,"elapsed":150,"user":{"displayName":"Sakai Calenda","userId":"05073622319816263783"}},"outputId":"c042a3f5-e7c4-409e-960b-bc628e90691e"},"id":"ksygTYxzrruY","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TCX27dSitFRk"},"id":"TCX27dSitFRk","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}